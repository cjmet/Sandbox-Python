{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1754608875655,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "uj4VCXyDksAk",
    "outputId": "d4bfc1ee-93f8-4b84-a420-6c52b8a26524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 1208,
     "status": "ok",
     "timestamp": 1754608876862,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "6XCMNruxk8mQ",
    "outputId": "9a590a80-4ec5-4df5-aaa8-5d61e0a092e1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; AI w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & AI w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('news_summary.csv', encoding = 'latin1')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1754608877461,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "mJR2GOlYlHvV",
    "outputId": "98cfa1e1-2154-460d-8425-b9b40ed65aa0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98396</th>\n",
       "      <td>CRPF jawan axed to death by Maoists in Chhatti...</td>\n",
       "      <td>A CRPF jawan was on Tuesday axed to death with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98397</th>\n",
       "      <td>First song from Sonakshi Sinha's 'Noor' titled...</td>\n",
       "      <td>'Uff Yeh', the first song from the Sonakshi Si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98398</th>\n",
       "      <td>'The Matrix' film to get a reboot: Reports</td>\n",
       "      <td>According to reports, a new version of the 199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98399</th>\n",
       "      <td>Snoop Dogg aims gun at clown dressed as Trump ...</td>\n",
       "      <td>A new music video shows rapper Snoop Dogg aimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98400</th>\n",
       "      <td>Madhesi Morcha withdraws support to Nepalese g...</td>\n",
       "      <td>Madhesi Morcha, an alliance of seven political...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "98396  CRPF jawan axed to death by Maoists in Chhatti...   \n",
       "98397  First song from Sonakshi Sinha's 'Noor' titled...   \n",
       "98398         'The Matrix' film to get a reboot: Reports   \n",
       "98399  Snoop Dogg aims gun at clown dressed as Trump ...   \n",
       "98400  Madhesi Morcha withdraws support to Nepalese g...   \n",
       "\n",
       "                                                    text  \n",
       "98396  A CRPF jawan was on Tuesday axed to death with...  \n",
       "98397  'Uff Yeh', the first song from the Sonakshi Si...  \n",
       "98398  According to reports, a new version of the 199...  \n",
       "98399  A new music video shows rapper Snoop Dogg aimi...  \n",
       "98400  Madhesi Morcha, an alliance of seven political...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1754608877469,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "EjN19HBTlWoc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\khaai\\AppData\\Local\\Temp\\ipykernel_5104\\1348631340.py:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  sentence = sentence.str.replace('[^0-9A-Za-z\\s]+', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(df, col):\n",
    "    # converting language data in data frame to lower case and then storing in sentence variable\n",
    "    sentence = df[col].str.lower()\n",
    "    sentence = sentence.str.replace('[^0-9A-Za-z\\s]+', '', regex=True)\n",
    "    sentence = sentence.str.normalize('NFD')\n",
    "    #encoding the string in sentence in UTF-8 format and ignoring errors if any\n",
    "    sentence = sentence.str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1988,
     "status": "ok",
     "timestamp": 1754608879456,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "vX6CDn-YlZNA"
   },
   "outputs": [],
   "source": [
    "dataset['headlines'] = preprocess_text(dataset, 'headlines')\n",
    "dataset['text'] = preprocess_text(dataset, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1754608879459,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "OrRT8tgwlc2k",
    "outputId": "2d3e0aab-91fc-4c4b-8629-8eee34958828"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98396</th>\n",
       "      <td>crpf jawan axed to death by maoists in chhatti...</td>\n",
       "      <td>a crpf jawan was on tuesday axed to death with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98397</th>\n",
       "      <td>first song from sonakshi sinhas noor titled uf...</td>\n",
       "      <td>uff yeh the first song from the sonakshi sinha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98398</th>\n",
       "      <td>the matrix film to get a reboot reports</td>\n",
       "      <td>according to reports a new version of the 1999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98399</th>\n",
       "      <td>snoop dogg aims gun at clown dressed as trump ...</td>\n",
       "      <td>a new music video shows rapper snoop dogg aimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98400</th>\n",
       "      <td>madhesi morcha withdraws support to nepalese g...</td>\n",
       "      <td>madhesi morcha an alliance of seven political ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "98396  crpf jawan axed to death by maoists in chhatti...   \n",
       "98397  first song from sonakshi sinhas noor titled uf...   \n",
       "98398            the matrix film to get a reboot reports   \n",
       "98399  snoop dogg aims gun at clown dressed as trump ...   \n",
       "98400  madhesi morcha withdraws support to nepalese g...   \n",
       "\n",
       "                                                    text  \n",
       "98396  a crpf jawan was on tuesday axed to death with...  \n",
       "98397  uff yeh the first song from the sonakshi sinha...  \n",
       "98398  according to reports a new version of the 1999...  \n",
       "98399  a new music video shows rapper snoop dogg aimi...  \n",
       "98400  madhesi morcha an alliance of seven political ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1754608879460,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "pkG3pSqklksd"
   },
   "outputs": [],
   "source": [
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "\n",
    "# make the token 1 and 2 ,0 is already reserved for the [pad]\n",
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0:'PAD',1: \"SOS\", 2: \"EOS\"}\n",
    "        self.n_words = 3  # Count SOS and EOS\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2412,
     "status": "ok",
     "timestamp": 1754608881872,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "tdaRnkTjlovv"
   },
   "outputs": [],
   "source": [
    "#create vocab instance\n",
    "vocab = Vocab()\n",
    "\n",
    "_ = dataset.text.apply(lambda x: vocab.add_sentence(x))\n",
    "_ = dataset.headlines.apply(lambda x: vocab.add_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1754608881887,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "di3UCQuZlrza",
    "outputId": "d35d74a2-8afb-4a0e-93c5-6e1dacce89ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120908"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1484,
     "status": "ok",
     "timestamp": 1754608883378,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "VsjG_zdRluM0"
   },
   "outputs": [],
   "source": [
    "#calculate and store the length of each text and headline\n",
    "dataset['text_length'] = dataset.text.str.split(' ').apply(lambda x: len(x))\n",
    "dataset['headlines_length'] = dataset.headlines.str.split(' ').apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1754608883443,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "u_Ci--9wlyTP",
    "outputId": "ced982e5-5b2d-483e-bad8-1b23505c9e41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(18), np.int64(92))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.headlines_length.max(), dataset.text_length.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1754608883444,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "dQfNPuZCl2GM"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH_INPUT = 100\n",
    "MAX_LENGTH_TARGET = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1754608883445,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "VacBnJ53l4D5"
   },
   "outputs": [],
   "source": [
    "# function to convert a sentence into a list of indices based on the vocabulary\n",
    "def indexes_from_sentence(vocab, sentence):\n",
    "    return [vocab.word2index[word] for word in sentence.split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1754608883445,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "I3BuXCrel6mk"
   },
   "outputs": [],
   "source": [
    "# convert a sentence into a list of indices, and then appends the EOS_token\n",
    "def tensor_from_sentence(vocab, sentence):\n",
    "    indexes = indexes_from_sentence(vocab, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1754608883446,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "5H9pI5bKl8v8"
   },
   "outputs": [],
   "source": [
    "# prepare dataloader\n",
    "def get_dataloader(dataset, batch_size):\n",
    "    n = dataset.shape[0]\n",
    "    input_ids = np.zeros((n, MAX_LENGTH_INPUT), dtype=np.int64)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH_TARGET), dtype=np.int64)\n",
    "\n",
    "    for idx in range(n):\n",
    "        inp_ids = indexes_from_sentence(vocab, dataset.text.iloc[idx])\n",
    "        tgt_ids = indexes_from_sentence(vocab, dataset.headlines.iloc[idx])\n",
    "\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1754608883447,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "KgfxgwBJmAuP"
   },
   "outputs": [],
   "source": [
    "#define encoder class\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # Make LSTM bidirectional\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # When LSTM is bidirectional, the output, hidden and cell state will be for both directions\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        return output, (hidden, cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1754608883517,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "YRlopYWomDds",
    "outputId": "327a9f06-3636-44bf-d3fd-f48e7dc19902"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (embedding): Embedding(100, 64)\n",
      "  (lstm): LSTM(64, 64, batch_first=True, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#initialize encoder\n",
    "enc = Encoder(100, 64)\n",
    "print(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1754608883518,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "aqx9eTDemG4N"
   },
   "outputs": [],
   "source": [
    "#creating simulated input\n",
    "x = torch.randint(1, 100, (1, 61))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1754608883805,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "kibjoTiLmJla"
   },
   "outputs": [],
   "source": [
    "#pass tensor x through encoder model\n",
    "enc_outputs, enc_hidden = enc.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1754608883815,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "55x6BzJrmL3Z",
    "outputId": "39238daf-fd60-42ef-88da-0401ae60881f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_outputs_shape: torch.Size([1, 61, 128])\n",
      "enc_hidden_h_shape: torch.Size([2, 1, 64])\n",
      "enc_hidden_c_shape: torch.Size([2, 1, 64])\n"
     ]
    }
   ],
   "source": [
    "enc_hidden_h_shape = enc_hidden[0].shape\n",
    "enc_hidden_c_shape = enc_hidden[1].shape\n",
    "enc_outputs_shape = enc_outputs.shape\n",
    "\n",
    "print(\"enc_outputs_shape:\", enc_outputs_shape)\n",
    "print(\"enc_hidden_h_shape:\", enc_hidden_h_shape)\n",
    "print(\"enc_hidden_c_shape:\", enc_hidden_c_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1754608883816,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "oPCistbomNxs"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size * 2  # Adjust hidden size if states are concatenated\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        # Assuming concatenation of hidden states, adjust LSTM input size\n",
    "        self.lstm = nn.LSTM(hidden_size, self.hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(self.hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "\n",
    "        # Combine or adapt encoder_hidden to suit unidirectional decoder\n",
    "        encoder_hidden = self.adapt_hidden(encoder_hidden)\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH_TARGET):\n",
    "            decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def adapt_hidden(self, hidden):\n",
    "        # Assuming hidden is a tuple (hidden_state, cell_state) each with dimensions [2, batch_size, hidden_size]\n",
    "        hidden_state, cell_state = hidden\n",
    "        # Concatenate the forward and backward states\n",
    "        hidden_state = torch.cat((hidden_state[0:hidden_state.size(0):2], hidden_state[1:hidden_state.size(0):2]), dim=2)\n",
    "        cell_state = torch.cat((cell_state[0:cell_state.size(0):2], cell_state[1:cell_state.size(0):2]), dim=2)\n",
    "        return (hidden_state, cell_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1754608883822,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "-tBt-SzqmRPW",
    "outputId": "12604e41-a291-4958-f6bd-050f07f97d81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate random target tensors\n",
    "tgt_tensor = torch.randint(1, 100, (1, 20))\n",
    "tgt_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1754608883831,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "CQJ23hksmStk"
   },
   "outputs": [],
   "source": [
    "#initialise the decoder class\n",
    "dec = Decoder(64, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1754608883833,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "9CgBy4tjmUGv"
   },
   "outputs": [],
   "source": [
    "# Assuming you have a device variable defined\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move your models to the designated device\n",
    "encoder = enc.to(device)\n",
    "decoder = dec.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1754608883868,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "Espde0CGmV59"
   },
   "outputs": [],
   "source": [
    "# When you load or create tensors, send them to the same device\n",
    "enc_outputs = enc_outputs.to(device)\n",
    "(h,c) = enc_hidden\n",
    "enc_hidden_gpu=h.to(device),c.to(device)\n",
    "tgt_tensor = tgt_tensor.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1754608883889,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "A3L7q80OmYfx"
   },
   "outputs": [],
   "source": [
    "#execute forward pass of decoder instance\n",
    "decoder_outputs, decoder_hidden= dec.forward(enc_outputs, enc_hidden_gpu, tgt_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1754608883898,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "pRf2DzklmZ92",
    "outputId": "ad7ec75e-1ca6-4bc4-80f4-3cc68c757516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_outputs_shape: torch.Size([1, 20, 100])\n",
      "decoder_hidden_h_shape: torch.Size([1, 1, 128])\n",
      "decoder_hidden_c_shape: torch.Size([1, 1, 128])\n"
     ]
    }
   ],
   "source": [
    "decoder_hidden_h_shape = decoder_hidden[0].shape\n",
    "decoder_hidden_c_shape = decoder_hidden[1].shape\n",
    "decoder_outputs_shape = decoder_outputs.shape\n",
    "\n",
    "print(\"decoder_outputs_shape:\", decoder_outputs_shape)\n",
    "print(\"decoder_hidden_h_shape:\", decoder_hidden_h_shape)\n",
    "print(\"decoder_hidden_c_shape:\", decoder_hidden_c_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 121,
     "status": "ok",
     "timestamp": 1754608884020,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "Bcnqc412mcD7",
    "outputId": "30b5c6ec-cd3f-454d-c0ac-e45b3fdbebaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 70848\n",
      "Validation set size: 7872\n",
      "Test set size: 19681\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = train_test_split(dataset, shuffle=True, test_size=0.2, random_state=42)\n",
    "train_dataset, val_dataset = train_test_split(train_dataset, shuffle=True, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"Train set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1754608884021,
     "user": {
      "displayName": "Chris Metcalfe",
      "userId": "13161867215133386378"
     },
     "user_tz": 240
    },
    "id": "0Qvwc1vimdnI"
   },
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    total_loss = 0\n",
    "    for input_tensor, target_tensor in tqdm(dataloader):\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate_model(dataloader, encoder, decoder, criterion):\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for input_tensor, target_tensor in tqdm(dataloader):\n",
    "            encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "            decoder_outputs, decoder_hidden = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "            loss = criterion(\n",
    "                decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "                target_tensor.view(-1)\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def train_model(train_dataloader, valid_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "                print_every=100, plot_every=100):\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        print(f\"Epoch: {epoch}/{n_epochs}\")\n",
    "        # Training\n",
    "        train_loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer,\n",
    "                                 decoder_optimizer, criterion)\n",
    "        print_loss_total += train_loss\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print(f\"Train Loss: {round(print_loss_avg, 3)}\")\n",
    "\n",
    "        # Validation\n",
    "        print('Validation....')\n",
    "        valid_loss = evaluate_model(valid_dataloader, encoder, decoder, criterion)\n",
    "        valid_losses.append(valid_loss)\n",
    "        print(f\"Validation Loss: {round(valid_loss, 3)}\")\n",
    "\n",
    "        # Save the model if it has the best validation loss so far\n",
    "        if valid_loss < best_val_loss:\n",
    "            best_val_loss = valid_loss\n",
    "            torch.save(encoder.state_dict(), 'best_encoder.pth')\n",
    "            torch.save(decoder.state_dict(), 'best_decoder.pth')\n",
    "            print(f\"Saved Best Model at Epoch: {epoch}\")\n",
    "\n",
    "    return train_losses, valid_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uvu873EGmgLh",
    "outputId": "a453b6c4-29e9-425e-dc3e-12fcd4f95bad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making DataLoaders .... .....  \n",
      "Defining Encoder and Decoder .....\n",
      "Epoch: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1107/1107 [05:00<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.731\n",
      "Validation....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:05<00:00, 22.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.243\n",
      "Saved Best Model at Epoch: 1\n",
      "Epoch: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1107/1107 [04:53<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.86\n",
      "Validation....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:05<00:00, 21.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.867\n",
      "Saved Best Model at Epoch: 2\n",
      "Epoch: 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1107/1107 [05:00<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.322\n",
      "Validation....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:05<00:00, 21.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.711\n",
      "Saved Best Model at Epoch: 3\n",
      "Epoch: 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1107/1107 [04:59<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.902\n",
      "Validation....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:05<00:00, 22.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.654\n",
      "Saved Best Model at Epoch: 4\n",
      "Epoch: 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1107/1107 [04:59<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.578\n",
      "Validation....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:05<00:00, 21.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.652\n",
      "Saved Best Model at Epoch: 5\n",
      "Epoch: 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1107/1107 [05:02<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.343\n",
      "Validation....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:05<00:00, 21.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.671\n",
      "Epoch: 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1107/1107 [04:57<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.166\n",
      "Validation....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:05<00:00, 20.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.719\n",
      "Epoch: 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1107/1107 [04:52<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.025\n",
      "Validation....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:05<00:00, 21.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.767\n",
      "Epoch: 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1107/1107 [05:00<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.908\n",
      "Validation....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:05<00:00, 21.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.829\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1107/1107 [04:59<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.808\n",
      "Validation....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:05<00:00, 21.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([3.7307284377993177,\n",
       "  2.8603443285314047,\n",
       "  2.3215775067674866,\n",
       "  1.902180323325091,\n",
       "  1.5775539711346578,\n",
       "  1.3429089572479194,\n",
       "  1.1661324346507038,\n",
       "  1.0251278963407742,\n",
       "  0.9077241382517035,\n",
       "  0.807822693761879],\n",
       " [3.2432793233452775,\n",
       "  2.866821323953024,\n",
       "  2.7105596317508356,\n",
       "  2.654367452714501,\n",
       "  2.651861826578776,\n",
       "  2.6714988685235745,\n",
       "  2.719182274205898,\n",
       "  2.7670969439715876,\n",
       "  2.8292864842143484,\n",
       "  2.875345516980179])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "batch_size = 64\n",
    "n_epochs =10\n",
    "print('Making DataLoaders .... .....  ')\n",
    "train_dataloader = get_dataloader(train_dataset, batch_size)\n",
    "val_dataloader=get_dataloader(val_dataset,batch_size)\n",
    "print('Defining Encoder and Decoder .....')\n",
    "encoder = Encoder(vocab.n_words, hidden_size).to(device)\n",
    "decoder = Decoder(hidden_size, vocab.n_words).to(device)\n",
    "\n",
    "train_model(train_dataloader, val_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=1, plot_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "mGpddvgRmiS5"
   },
   "outputs": [],
   "source": [
    "def evaluate_test_samples(encoder, decoder, sentence, vocab):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensor_from_sentence(vocab, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(vocab.index2word[idx.item()])\n",
    "\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "V6w-lJqbmkdt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\khaai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\khaai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\khaai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "def evaluateRandomly_train(encoder, decoder, vocab, n=10):\n",
    "    for i in range(n):\n",
    "        print(i)\n",
    "        eval_sample = train_dataset.iloc[i:i+1, :]\n",
    "        print('news_article > ', eval_sample['text'].iloc[0])\n",
    "        headline = eval_sample['headlines'].iloc[0]\n",
    "        print('original_headline = ', headline)\n",
    "        output_words = evaluate_test_samples(encoder, decoder, eval_sample.text.iloc[0], vocab)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('predicted_headline < ', output_sentence)\n",
    "        print(f\"meteor score: {nltk.translate.meteor_score.single_meteor_score(headline.split(), output_sentence.split())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "QuIpJtw_mmW7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "news_article >  a study by financial services company ubs has revealed a person working in mumbai has to work 1147 days to afford the iphone x while a delhi person has to work 1005 days for the same a cairo person has to work the most for 1332 days while a person in zurich can afford iphone x in only 47 days\n",
      "original_headline =  how many days one has to work around the world to buy iphone x\n",
      "predicted_headline <  iphone x days <EOS>\n",
      "meteor score: 0.19658119658119655\n",
      "1\n",
      "news_article >  catalonias independence from spain would not enjoy international recognition france said on monday ahead of catalan regional governments announcement of last weeks independence vote result this crisis needs to be resolved through dialogue at all levels of spanish politics france urged earlier catalonia had claimed that 90 of the participants voted in favour of independence\n",
      "original_headline =  catalan independence would not be recognised france\n",
      "predicted_headline <  catalan spain <EOS>\n",
      "meteor score: 0.07575757575757576\n",
      "2\n",
      "news_article >  an international team of researchers has claimed the ambitious paris climate goal to limit global warming at 15c by 2100 is still possible a researcher associated with the new analysis said in 2015 the carbon cuts needed were incompatible with democracy however with the current dip in prices of renewables a 66 chance of meeting the goal still exists\n",
      "original_headline =  paris deals 15c limit still achievable claims new study\n",
      "predicted_headline <  paris rate rate <EOS>\n",
      "meteor score: 0.058823529411764705\n",
      "3\n",
      "news_article >  ahead of pm narendra modis visit to dehraduns forest research institute on international yoga day uttarakhands forest department has started a drive to clear the area of snakes and monkeys we dont want any inconvenience for the participants as the campus has a dense forest we have so far caught and released two snakes divisional forest officer rajeev dhiman said\n",
      "original_headline =  yoga day venue to be cleared of snakes ahead of pms visit\n",
      "predicted_headline <  yoga day venue <EOS>\n",
      "meteor score: 0.2628968253968254\n",
      "4\n",
      "news_article >  police on tuesday arrested around 70 gangsters after crashing the birthday party of their kingpin in chennai the police were acting on an intel and intercepted a car that was carrying some of the gangsters to the venue the police reached the venue when the kingpin who managed to escape later was cutting his birthday cake with a machete\n",
      "original_headline =  chennai police crash birthday party arrest 70 gangsters\n",
      "predicted_headline <  police officer <EOS>\n",
      "meteor score: 0.06666666666666667\n",
      "5\n",
      "news_article >  france will make school education compulsory from the age of three instead of six president emmanuel macron announced on tuesday the move is a part of the governments reform to make education accessible to everyone irrespective of their financial status as per government records nearly 98 french children are enrolled at school at the age of three\n",
      "original_headline =  france to make school education compulsory from age 3\n",
      "predicted_headline <  france <EOS>\n",
      "meteor score: 0.06024096385542168\n",
      "6\n",
      "news_article >  pope francis was hit by an object resembling a towel thrown at him from the crowds gathered in chiles capital santiago the pontiff who was unharmed ignored the action and smiled notably popes visit was marked by protests over alleged sexual abuse of children within the catholic church\n",
      "original_headline =  video pope francis hit by object during his chile visit\n",
      "predicted_headline <  pope francis in egypt <EOS>\n",
      "meteor score: 0.19736842105263158\n",
      "7\n",
      "news_article >  dubai plans to develop a 17 billion over 10000 crore tourist resort on two manmade islands it is building on either side of the burj al arab a luxury sailshaped hotel marsa al arab will comprise two islands one for family tourism and the second featuring luxury villas and a private marina the project will be completed by late 2020 \n",
      "original_headline =  dubai plans 10000 crore project on new artificial islands\n",
      "predicted_headline <  dubai dubai <EOS>\n",
      "meteor score: 0.05952380952380952\n",
      "8\n",
      "news_article >  former world number ones roger federer and novak djokovic have called for an increase in the pay players earn at the grand slam tournaments australian open tournament director craig tiley has reportedly outlined plans to boost prize money at the opening grand slam of the year from 55 million to 100 million over the next five years\n",
      "original_headline =  federer djokovic call for higher prize money at grand slams\n",
      "predicted_headline <  djokovic federer <EOS>\n",
      "meteor score: 0.10752688172043011\n",
      "9\n",
      "news_article >  the uttar pradesh police on tuesday denied media reports clarifying that it had nothing to do with the arrest of eight donkeys which were reportedly jailed for four days for eating plants worth 5 lakh reports had quoted jail authorities claiming the donkeys which were let loose by the owner despite a warning were jailed for destroying the expensive plants\n",
      "original_headline =  up police denies report it jailed donkeys for eating plants\n",
      "predicted_headline <  up police report <EOS>\n",
      "meteor score: 0.27186761229314416\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "evaluateRandomly_train(encoder, decoder, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "7dxk6wKNmqma"
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly_test(encoder, decoder, vocab, n=10):\n",
    "    for i in range(n):\n",
    "        print(i)\n",
    "        eval_sample = test_dataset.iloc[i:i+1, :]\n",
    "        print('news_article > ', eval_sample['text'].iloc[0])\n",
    "        headline = eval_sample['headlines'].iloc[0]\n",
    "        print('original_headline = ', headline)\n",
    "        output_words = evaluate_test_samples(encoder, decoder, eval_sample.text.iloc[0], vocab)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('predicted_headline < ', output_sentence)\n",
    "        print('')\n",
    "        print(f\"'meteor score:' {nltk.translate.meteor_score.single_meteor_score(headline.split(), output_sentence.split())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "pIZEGbYHmslB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "news_article >  students in karnataka will get extra marks if their parents cast votes in the upcoming assembly elections the associated management of primary and secondary schools has announced the encouraging marks will be added in the 201819 academic year the association said after casting their votes parents can visit member schoolsand confirm that they voted by showing the indelible ink mark\n",
      "original_headline =  ktaka students to get extra marks if parents vote in polls\n",
      "predicted_headline <  ktaka parents to be displayed <EOS>\n",
      "\n",
      "'meteor score:' 0.14285714285714285\n",
      "1\n",
      "news_article >  syrian antiaircraft defences on monday shot down missiles over two air bases syrias state media said the missiles targeted shayrat air base in the homs province and another base northeast of the capital damascus this comes days after the us uk and france launched air strikes on syrian chemical weapons facilities in retaliation for the alleged chemical attack in douma\n",
      "original_headline =  syria shoots down missiles fired at two air bases\n",
      "predicted_headline <  syrian syrian syrian missiles <EOS>\n",
      "\n",
      "'meteor score:' 0.05813953488372093\n",
      "2\n",
      "news_article >  a dinosaurlike creatures fossil was found during an excavation on sunday in uttarakhands jaspur a small city 110 km from nainital the fossils hind legs measure around 29 cm while the tail is around 5 cm long found at an abandoned electricity department land the authorities would be sending the remains to dehradunbased wildlife institute of india for further investigation\n",
      "original_headline =  dinosaurlike animals fossil found in uttarakhand\n",
      "predicted_headline <  doctor found in forest <EOS>\n",
      "\n",
      "'meteor score:' 0.3177966101694915\n",
      "3\n",
      "news_article >  the uttar pradesh government is planning to form a up muslim waqf board by merging the separate shia and sunni waqf boards to prevent wastage of funds minister of state for waqf mohsin raza said the merged waqf board will have members from both the communities and its chairman will be selected from among them he added \n",
      "original_headline =  up may merge shia sunni waqf boards to prevent fund wastage\n",
      "predicted_headline <  up govt <EOS>\n",
      "\n",
      "'meteor score:' 0.049019607843137254\n",
      "4\n",
      "news_article >  egyptian activistactress amal fathy has been given a sentence of two years on charges of spreading false news for uploading a video on facebook wherein she alleged that she faced sexual harassment at a bank fathy was charged with disseminating a video on social media to publicly incite overthrowing the government she has already spent over 140 days in prison\n",
      "original_headline =  egypt actress gets 2 yrs jail for fake news on sexual harassment\n",
      "predicted_headline <  egypt militant <EOS>\n",
      "\n",
      "'meteor score:' 0.04504504504504504\n",
      "5\n",
      "news_article >  worlds richest person and amazon ceo jeff bezos added 326 billion to his wealth in 2017 which is higher than the gdp of 93 countries according to figures from imf it is also more than the combined gdp for one year of 28 countries bezos net worth is currently 106 billion after amazon shares surged by over 6 this year\n",
      "original_headline =  jeff bezos added more wealth in 2017 than gdp of 93 nations\n",
      "predicted_headline <  bezos bezos <EOS>\n",
      "\n",
      "'meteor score:' 0.04504504504504504\n",
      "6\n",
      "news_article >  bangladesh cricket teams limited overs captain mashrafe mortaza on tuesday announced that he will retire from t20 international cricket after the end of the series against sri lanka the 33yearold pace bowler has featured in 52 t20i matches for his nation so far picking up 39 wickets and registering 368 runs at an average of 1362\n",
      "original_headline =  bangladeshi captain mortaza announces retirement from t20is\n",
      "predicted_headline <  bangladesh keeper captain <EOS>\n",
      "\n",
      "'meteor score:' 0.07462686567164178\n",
      "7\n",
      "news_article >  mexican drug lord joaquin el chapo guzman has claimed that his extradition to us from mexico violated the terms of a usmexico treaty according to the terms guzman had to be transferred to either california or texas however on the day of his extradition mexico waived the terms and consented instead to send him to new york guzmans lawyers said\n",
      "original_headline =  mexican drug lord el chapo questions us extradition legality\n",
      "predicted_headline <  mexican mexico mexico <EOS>\n",
      "\n",
      "'meteor score:' 0.058823529411764705\n",
      "8\n",
      "news_article >  independent united nations un monitors have accused north korea of supplying ballistic missile systems along with conventional weapons including rocket launchers and surfacetoair missiles to myanmar in a report to the un security councils sanctions committee the monitors also accused north korea of supplying weapons to syria and violating un sanctions by exporting banned commodities \n",
      "original_headline =  n korea supplies ballistic missiles to myanmar un monitors \n",
      "predicted_headline <  un un sanctions un <EOS>\n",
      "\n",
      "'meteor score:' 0.05813953488372093\n",
      "9\n",
      "news_article >  after reports of three amrapali group companies going into insolvency surfaced several home buyers slammed cricketer harbhajan singh who was once the brand ambassador of the company a user claimed that harbhajan and ms dhoni had received free flats from the company while he lost his money harbhajan responded saying even he was made a fool by the company\n",
      "original_headline =  thenga mila hamme harbhajan responds to home buyers\n",
      "predicted_headline <  got 1 stake buy wife <EOS>\n",
      "\n",
      "'meteor score:' 0.0\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "evaluateRandomly_test(encoder, decoder, vocab)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1FC7a74DX9OYNK3rD31Vsd388jdxNzKp4",
     "timestamp": 1754605857110
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
