{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9967e22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-5-nano R 2500tk minimal default \n",
      "Usage: 8 + 15 = 23\t 1/10,000¢\n",
      "Prompt: Hello.\n",
      "Response: {'text': 'Hello! How can I help you today?', 'id': 'resp_68c3637a13d4819d8a5bdce99195f2af059183524d047e25', 'model': 'gpt-5-nano', 'service_tier': 'default', 'usage': ResponseUsage(input_tokens=8, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=15, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=23)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "default_model = \"gpt-5-nano\"\n",
    "def generate_response(): None\n",
    "def divider(): None\n",
    "%run OpenAi.ipynb\n",
    "\n",
    "test_prompt = \"Hello.\"\n",
    "response = generate_response(test_prompt, verbose=True)\n",
    "print(f\"Prompt: {test_prompt}\\nResponse: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03868577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-5-nano R 2500tk minimal default \n",
      "Prompt: Explain AI in one sentence.\n",
      "Response: Response(id='resp_68c3637cf5048193a7e0ede0e5f1395007cf1862494585bf', created_at=1757635453.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-nano-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_68c3637dc3d8819382de06166e1ed4aa07cf1862494585bf', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_68c3637dd968819380b23f52824969ae07cf1862494585bf', content=[ResponseOutputText(annotations=[], text='Artificial intelligence is the field of computer science focused on creating systems that can perceive, reason, learn, and act to perform tasks that typically require human intelligence.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=2500, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key='test_user', reasoning=Reasoning(effort='minimal', generate_summary=None, summary=None), safety_identifier='test_user', service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=12, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=37, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=49), user=None, store=True)\n",
      "Usage: 12 + 37 = 49\t 1/10,000¢\n",
      "Basic Prompt\n",
      "Prompt: Explain AI in one sentence.\n",
      "Response: {'text': 'Artificial intelligence is the field of computer science focused on creating systems that can perceive, reason, learn, and act to perform tasks that typically require human intelligence.', 'id': 'resp_68c3637cf5048193a7e0ede0e5f1395007cf1862494585bf', 'model': 'gpt-5-nano', 'service_tier': 'default', 'usage': ResponseUsage(input_tokens=12, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=37, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=49)}\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example: Basic prompt\n",
    "basic_prompt = \"Explain AI in one sentence.\"\n",
    "response = generate_response(basic_prompt, debug=True)\n",
    "print(\"Basic Prompt\")\n",
    "print(f\"Prompt: {basic_prompt}\\nResponse: {response}\\n\")\n",
    "divider()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76c9b09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4.1-nano R 2500tk 0.8° default \n",
      "Prompt: Classify this sentiment: 'I love this product!'\n",
      "Response: Response(id='resp_68c3637fc24c819fb77a6c812a951c220075c6cbb912c61f', created_at=1757635455.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-nano-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_68c363803564819fa91f61bb92c43dce0075c6cbb912c61f', content=[ResponseOutputText(annotations=[], text='The sentiment of \"I love this product!\" is positive.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=0.8, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=2500, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key='test_user', reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier='test_user', service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=18, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=13, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=31), user=None, store=True)\n",
      "Usage: 18 + 13 = 31\t 1/10,000¢\n",
      "Zero-shot Prompt\n",
      "Prompt: Classify this sentiment: 'I love this product!'\n",
      "Response: {'text': 'The sentiment of \"I love this product!\" is positive.', 'id': 'resp_68c3637fc24c819fb77a6c812a951c220075c6cbb912c61f', 'model': 'gpt-4.1-nano', 'service_tier': 'default', 'usage': ResponseUsage(input_tokens=18, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=13, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=31)}\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example: Zero-shot, few-shot, and CoT prompts\n",
    "zero_shot_prompt = \"Classify this sentiment: 'I love this product!'\"\n",
    "zero_response = generate_response(zero_shot_prompt, temperature=0.8, debug=True)\n",
    "print(\"Zero-shot Prompt\")\n",
    "print(f\"Prompt: {zero_shot_prompt}\\nResponse: {zero_response}\\n\")\n",
    "divider()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80d9c9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4.1-nano R 2500tk 0.9p default \n",
      "Prompt:                  \n",
      "Example 1: Text: 'Great movie.' Sentiment: Positive.\n",
      "Example 2: Text: 'Terrible service.' Sentiment: Negative.\n",
      "Classify: 'Okay experience.'\n",
      "\n",
      "Response: Response(id='resp_68c36382d374819288ff8a2adff0b5eb04d08de026b5d829', created_at=1757635458.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-nano-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_68c3638317108192aa994ab29521492e04d08de026b5d829', content=[ResponseOutputText(annotations=[], text='The sentiment of the text \"Okay experience.\" can be classified as Neutral, since it suggests an average or middling experience without clear positive or negative emotions.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=0.9, background=False, max_output_tokens=2500, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key='test_user', reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier='test_user', service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=46, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=32, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=78), user=None, store=True)\n",
      "Usage: 46 + 32 = 78\t 1/10,000¢\n",
      "Few-shot Prompt\n",
      "Prompt: \n",
      "Example 1: Text: 'Great movie.' Sentiment: Positive.\n",
      "Example 2: Text: 'Terrible service.' Sentiment: Negative.\n",
      "Classify: 'Okay experience.'\n",
      "\n",
      "Response: {'text': 'The sentiment of the text \"Okay experience.\" can be classified as Neutral, since it suggests an average or middling experience without clear positive or negative emotions.', 'id': 'resp_68c36382d374819288ff8a2adff0b5eb04d08de026b5d829', 'model': 'gpt-4.1-nano', 'service_tier': 'default', 'usage': ResponseUsage(input_tokens=46, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=32, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=78)}\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Few-shot example\n",
    "few_shot_prompt = \"\"\"\n",
    "Example 1: Text: 'Great movie.' Sentiment: Positive.\n",
    "Example 2: Text: 'Terrible service.' Sentiment: Negative.\n",
    "Classify: 'Okay experience.'\n",
    "\"\"\"\n",
    "few_response = generate_response(few_shot_prompt, top_p=0.9, debug=True)  # Now supported\n",
    "print(\"Few-shot Prompt\")\n",
    "print(f\"Prompt: {few_shot_prompt}\\nResponse: {few_response}\\n\")\n",
    "divider()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec51b928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4.1-nano R 2500tk 0.2° default \n",
      "Prompt: Solve: What is 15% of 200? Think step by step.\n",
      "Response: Response(id='resp_68c3638647cc81908345c8ea541185e40a999c5eaac8fbde', created_at=1757635462.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-nano-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_68c363880b488190baa356dbbc1c3be90a999c5eaac8fbde', content=[ResponseOutputText(annotations=[], text=\"Let's find 15% of 200 step by step.\\n\\n**Step 1:** Convert the percentage to a decimal.\\n15% = 15/100 = 0.15\\n\\n**Step 2:** Multiply the decimal by the number.\\n0.15 × 200\\n\\n**Step 3:** Perform the multiplication.\\n0.15 × 200 = (0.15 × 200) = 30\\n\\n**Answer:** 15% of 200 is **30**.\", type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=0.2, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=2500, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key='test_user', reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier='test_user', service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=23, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=99, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=122), user=None, store=True)\n",
      "Usage: 23 + 99 = 122\t 1/1,000¢\n",
      "CoT Prompt\n",
      "Prompt: Solve: What is 15% of 200? Think step by step.\n",
      "Response: {'text': \"Let's find 15% of 200 step by step.\\n\\n**Step 1:** Convert the percentage to a decimal.\\n15% = 15/100 = 0.15\\n\\n**Step 2:** Multiply the decimal by the number.\\n0.15 × 200\\n\\n**Step 3:** Perform the multiplication.\\n0.15 × 200 = (0.15 × 200) = 30\\n\\n**Answer:** 15% of 200 is **30**.\", 'id': 'resp_68c3638647cc81908345c8ea541185e40a999c5eaac8fbde', 'model': 'gpt-4.1-nano', 'service_tier': 'default', 'usage': ResponseUsage(input_tokens=23, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=99, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=122)}\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Chain of Thought (CoT) example\n",
    "cot_prompt = \"Solve: What is 15% of 200? Think step by step.\"\n",
    "cot_response = generate_response(cot_prompt, temperature=0.2, debug=True)\n",
    "print(\"CoT Prompt\")\n",
    "print(f\"Prompt: {cot_prompt}\\nResponse: {cot_response}\\n\")\n",
    "divider()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "310ea197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4.1-nano C 2500tk 42r default \n",
      "Error generating response: Completions.create() got an unexpected keyword argument 'previous_response_id'\n",
      "Random Seed (test)\n",
      "Prompt: Generate me a Random Number, between 1 and 10000\n",
      "Response: None\n",
      "\n",
      "--------------------------------------------------\n",
      "gpt-4.1-nano C 2500tk 42r default \n",
      "Error generating response: Completions.create() got an unexpected keyword argument 'previous_response_id'\n",
      "Random Seed (confirm)\n",
      "Prompt: Generate me a Random Number, between 1 and 10000\n",
      "Response: None\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Random Seed and Temperature as Prompt, since they are not supported in the response api\n",
    "seed_prompt = \"Generate me a Random Number, between 1 and 10000\"\n",
    "seed_response = generate_response(seed_prompt, seed=42,debug=True)\n",
    "print(\"Random Seed (test)\")\n",
    "print(f\"Prompt: {seed_prompt}\\nResponse: {seed_response}\\n\")\n",
    "divider()\n",
    "\n",
    "seed_prompt = \"Generate me a Random Number, between 1 and 10000\"\n",
    "seed_response = generate_response(seed_prompt, seed=42, debug=True)\n",
    "print(\"Random Seed (confirm)\")\n",
    "print(f\"Prompt: {seed_prompt}\\nResponse: {seed_response}\\n\")\n",
    "divider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7819d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of recent edits\n"
     ]
    }
   ],
   "source": [
    "print(\"End of recent edits\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
